# Plan Semaine 1 : Data & Machine Learning (Le Socle)

Cette semaine est cruciale. Nous allons construire les fondations du projet : les donnÃ©es et le premier modÃ¨le de rÃ©fÃ©rence. Si cette Ã©tape est ratÃ©e, les modÃ¨les complexes (LSTM) ne fonctionneront pas.

## ğŸ“‚ Architecture de la Semaine 1

```
DM Project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # DonnÃ©es brutes tÃ©lÃ©chargÃ©es (stock_prices.csv)
â”‚   â””â”€â”€ processed/          # DonnÃ©es avec indicateurs (features.csv)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_data_collection.ipynb    # TÃ¢che 1 : TÃ©lÃ©chargement & Nettoyage
â”‚   â”œâ”€â”€ 2_feature_engineering.ipynb # TÃ¢che 2 : CrÃ©ation des indicateurs (RSI, MACD)
â”‚   â””â”€â”€ 3_baseline_vs_xgboost.ipynb # TÃ¢che 3 : ModÃ¨les (NaÃ¯f vs XGBoost)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py      # Fonctions pour charger les donnÃ©es
â”‚   â””â”€â”€ features.py         # Fonctions pour calculer RSI, MACD (rÃ©utilisable)
â””â”€â”€ requirements.txt        # BibliothÃ¨ques nÃ©cessaires
```

## âœ… Liste des TÃ¢ches (To-Do List)

### Jour 1 : DonnÃ©es & Exploration
- [ ] **Installation** : Installer les librairies (`pip install -r requirements.txt`).
- [ ] **Collecte** : TÃ©lÃ©charger les donnÃ©es via `yfinance` (AAPL, MSFT, TSLA, SP500, VIX, TNX).
- [ ] **Nettoyage** : GÃ©rer les jours fÃ©riÃ©s et les valeurs manquantes (interpolation).
- [ ] **Visualisation** : Tracer les courbes de prix et de volume. VÃ©rifier la corrÃ©lation avec le VIX.

### Jour 2 : Feature Engineering (La "Recette SecrÃ¨te")
- [ ] **Indicateurs Techniques** : Calculer RSI, MACD, Bollinger Bands, ATR.
- [ ] **StationnaritÃ©** : CrÃ©er la variable cible `Log_Return` (Rendement Logarithmique) au lieu du Prix.
- [ ] **Lags** : CrÃ©er les variables retardÃ©es (t-1, t-2, t-3) pour donner de la "mÃ©moire" au modÃ¨le ML.
- [ ] **Split** : Diviser en Train (2020-2023) / Val (2024) / Test (2025).

### Jour 3 : ModÃ©lisation Initiale
- [ ] **Baseline NaÃ¯ve** : ImplÃ©menter la prÃ©diction "Demain = Aujourd'hui". Calculer le RMSE et la PrÃ©cision Directionnelle.
- [ ] **XGBoost** : EntraÃ®ner un modÃ¨le XGBoost sur les features crÃ©Ã©es.
- [ ] **Comparaison** : Le XGBoost bat-il la Baseline ? Si oui, de combien ?
- [ ] **Analyse** : Regarder la "Feature Importance" (Quels indicateurs comptent le plus ?).

---

## ğŸš€ Objectif de fin de semaine
Avoir un tableau comparatif simple :
| ModÃ¨le | RMSE | Directional Accuracy |
| :--- | :--- | :--- |
| Naive | 1.5% | 50% |
| XGBoost | 1.2% | 54% |
